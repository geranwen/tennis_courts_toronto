{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment\n",
    "Run this under tf-cpu3 envr, although probably no longer needed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import quopri\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read files and extract elements\n",
    "\n",
    "Load from downloaded html page with dynamically loaded contents, since the raw HTML didn't include the actual listings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the file\n",
    "with open(\"tennis_listing.mhtml\", \"r\", encoding='utf-8') as f:\n",
    "    content = f.read()\n",
    "\n",
    "# Decode the Quoted-Printable encoding\n",
    "decoded_content = quopri.decodestring(content).decode('utf-8')\n",
    "\n",
    "# Parse the page content\n",
    "soup = BeautifulSoup(decoded_content, 'lxml')\n",
    "\n",
    "# Find the table in the page content\n",
    "table = soup.find('table')\n",
    "\n",
    "# Get all rows in the table\n",
    "rows = table.find_all('tr')\n",
    "\n",
    "# Get the column headers\n",
    "headers = [th.text.strip() for th in rows[0].find_all('th')]\n",
    "\n",
    "# Initialize empty list to hold the row data\n",
    "data = []\n",
    "\n",
    "# Iterate over the rows, starting from the second one (as the first one is the header)\n",
    "for row in rows[1:]:\n",
    "    # Get the tds in the row\n",
    "    tds = row.find_all('td')\n",
    "\n",
    "    # Extract the desired data from the tds based on data-info attribute\n",
    "    location = next((td.text for td in tds if td.get('data-info') == 'Location'), '')\n",
    "    public_hours = next((td.text for td in tds if td.get('data-info') == 'Public Hours'), '')\n",
    "    winter_play = next((td.get_text().strip() for td in tds if td.get('data-info') == 'WinterPlay'), 'NA')\n",
    "    type = next((td.get_text().strip() for td in tds if td.get('data-info') == 'Type'), '')\n",
    "    lights = next((td.get_text().strip() for td in tds if td.get('data-info') == 'Lights'), '')\n",
    "    courts = next((td.get_text().strip() for td in tds if td.get('data-info') == 'Courts'), '')\n",
    "\n",
    "    # Append the data to the list\n",
    "    data.append([location, public_hours, winter_play, type, lights, courts])\n",
    "\n",
    "# Create a DataFrame with the data\n",
    "df = pd.DataFrame(data, columns=['location', 'public_hours', 'winter_play', 'type', 'lights', 'courts'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate df['location'] into 2 columns based, putting everything before 'Club:' into df['club'] and everything after into df['additional'] \n",
    "df[['place','additional']] = df['location'].str.split('Club:',expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Geran\\Projects\\toronto_tennis_courts\\data_grab.ipynb Cell 6\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Geran/Projects/toronto_tennis_courts/data_grab.ipynb#W5sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m         longitudes\u001b[39m.\u001b[39mappend(\u001b[39mNone\u001b[39;00m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Geran/Projects/toronto_tennis_courts/data_grab.ipynb#W5sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m     \u001b[39m# Sleep for 1 second to avoid hitting the rate limit\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Geran/Projects/toronto_tennis_courts/data_grab.ipynb#W5sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m     time\u001b[39m.\u001b[39;49msleep(\u001b[39m1\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Geran/Projects/toronto_tennis_courts/data_grab.ipynb#W5sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m \u001b[39m# Add the latitudes and longitudes to the dataframe\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Geran/Projects/toronto_tennis_courts/data_grab.ipynb#W5sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mlatitude\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m latitudes\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# use geocoders to get long and lat for each place\n",
    "from geopy.geocoders import Nominatim\n",
    "import time\n",
    "\n",
    "geolocator = Nominatim(user_agent=\"geoapi_tenniscourts_toronto_test\")\n",
    "\n",
    "# Initialize lists to store the latitudes and longitudes\n",
    "latitudes = []\n",
    "longitudes = []\n",
    "\n",
    "# Iterate over the places\n",
    "for place in df['place']:\n",
    "    # Add \"Toronto\" to the place name to improve geocoding accuracy\n",
    "    location = geolocator.geocode(f\"{place}, Toronto\")\n",
    "\n",
    "    # Check if the geocoding was successful\n",
    "    if location is not None:\n",
    "        # If it was, append the latitude and longitude to the lists\n",
    "        latitudes.append(location.latitude)\n",
    "        longitudes.append(location.longitude)\n",
    "    else:\n",
    "        # If it wasn't, append a missing value\n",
    "        latitudes.append(None)\n",
    "        longitudes.append(None)\n",
    "\n",
    "    # Sleep for 1 second to avoid hitting the rate limit\n",
    "    time.sleep(1)\n",
    "\n",
    "# Add the latitudes and longitudes to the dataframe\n",
    "df['latitude'] = latitudes\n",
    "df['longitude'] = longitudes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get subset of df where latitude and longitude are null\n",
    "df_null = df[df[['latitude', 'longitude']].isnull().any(axis=1)]\n",
    "# replace df_null['place'] with the part of df_null['location'] before ' Book Online'\n",
    "df_null['place'] = df_null['place'].str.split(' Book Online',expand=True)[0]\n",
    "# replace df_null['place'] with the part of df_null['place'] before ' -'\n",
    "df_null['place'] = df_null['place'].str.split(' -',expand=True)[0]\n",
    "# replace df_null['place'] with the part of df_null['place'] before comma ','\n",
    "df_null['place'] = df_null['place'].str.split(',',expand=True)[0]\n",
    "df_null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modify code to get long and lat for places missed the 1st time.\n",
    "\n",
    "from geopy.geocoders import Nominatim\n",
    "import time\n",
    "\n",
    "geolocator = Nominatim(user_agent=\"geoapi_tenniscourts_toronto_test\")\n",
    "\n",
    "# Initialize lists to store the latitudes and longitudes\n",
    "latitudes = []\n",
    "longitudes = []\n",
    "\n",
    "# Iterate over the places\n",
    "for place in df_null['place']:\n",
    "    # Add \"Toronto\" to the place name to improve geocoding accuracy\n",
    "    location = geolocator.geocode(f\"{place}, Toronto\")\n",
    "\n",
    "    # Check if the geocoding was successful\n",
    "    if location is not None:\n",
    "        # If it was, append the latitude and longitude to the lists\n",
    "        latitudes.append(location.latitude)\n",
    "        longitudes.append(location.longitude)\n",
    "    else:\n",
    "        # If it wasn't, append a missing value\n",
    "        latitudes.append(None)\n",
    "        longitudes.append(None)\n",
    "\n",
    "    # Sleep for 1 second to avoid hitting the rate limit\n",
    "    time.sleep(1)\n",
    "\n",
    "# Add the latitudes and longitudes to the dataframe\n",
    "df_null['latitude'] = latitudes\n",
    "df_null['longitude'] = longitudes\n",
    "\n",
    "df_null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Combine both dataframes\n",
    "\n",
    "# load tennis_courts_toronto_cleaned.csv to df_manual\n",
    "df_manual = pd.read_csv('tennis_courts_toronto_null.csv')\n",
    "\n",
    "# concat df_manual with df and remove duplicates based on location and keep the one from df_mannual\n",
    "df_merged = pd.concat([df, df_manual]).drop_duplicates(subset=['location'], keep='last')\n",
    "df_merged\n",
    "\n",
    "# count null values in df_merged for latitude and longitude\n",
    "df_merged.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `df_manual` file, loaded from the csv file, involved some mannual work to cover the courts that was missed by the geocoder package. The results are merged, and saved to an external csv file in the code block below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save df_merged to csv\n",
    "# df_merged.to_csv('tennis_courts_toronto_full_cleaned.csv', index=False)\n",
    "\n",
    "# load df_merged from csv\n",
    "df_complete = pd.read_csv('tennis_courts_toronto_full_cleaned.csv')\n",
    "df_complete"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot map and show results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save df_merged to csv\n",
    "# df_merged.to_csv('tennis_courts_toronto_full_cleaned.csv', index=False)\n",
    "\n",
    "# load df_merged from csv\n",
    "df_complete = pd.read_csv('tennis_courts_toronto_full_cleaned.csv')\n",
    "df_complete\n",
    "\n",
    "\n",
    "import folium\n",
    "\n",
    "# Create a map centered at an approximate location of Toronto\n",
    "map_toronto = folium.Map(location=[43.70, -79.42], zoom_start=11)\n",
    "\n",
    "# filter\n",
    "df_complete = df_complete[df_complete['type'] == 'Public']\n",
    "# df_complete = df_complete[df_complete['lights'] == 'Yes']\n",
    "\n",
    "# Add a marker for each tennis club to the map\n",
    "for index, row in df_complete.iterrows():\n",
    "    folium.Marker(\n",
    "        location=[row['latitude'], row['longitude']],\n",
    "        popup=row['place'],  # this will show the name of the place when you click on the marker\n",
    "    ).add_to(map_toronto)\n",
    "\n",
    "# Display the map\n",
    "map_toronto\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-cpu3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
